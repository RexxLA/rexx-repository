%Compile with latexmk -lualatex
% If using texworks, define a Typeset menu option for latexmk with
%    -lualatex
%    -synctex
%    $fullname
%
% Changes
% Table of contents
% \underline{default}
% Split nomenclature section
% Link to 3.9 Unicode Encoding Forms
% Codepoints/EGCs option in support of charin()
% Correct and expand constants example
% Index
% stream - seek and update
% TUTOR
% Reference ARB GitHub issues
%
% \documentclass[draft]{article}
\documentclass[b4paper]{article}
\usepackage[
    backend=biber,%
    backref=true,%
    indexing=true,%
    sorting=anyt,%,
    style=alphabetic%
    ]%
    {biblatex}
\addbibresource{ARB.bib}
\addbibresource{FAQ.bib}
\addbibresource{IETF.bib}
\addbibresource{ISO.bib}
\addbibresource{Unicode.bib}
\usepackage{enumitem}
\usepackage{eqparbox}
\usepackage{expl3}
\usepackage{fontspec}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{ifthen}
\usepackage{imakeidx}
\usepackage{listings}         %Requires luatex engine to handle UTF-8
                              %Consider using minted, but ...
\usepackage{makeidx}
\usepackage{tocbibind}
\usepackage{upquote}
\usepackage{cleveref}

\defbibcheck{standard}{\iffieldequalstr{type}{standard}{}{\skipentry}}

\makeindex[intoc]

\setmainfont{CMU Serif}
% texlive-cm-unicode or retrieve cm-unicode with MikTex Console

\newlist{definition}{description}{2} % <- pick a larger number if you want to nest these
\setlist[definition]{
    labelwidth=\eqboxwidth{listlabel@\EnumitemId},
    leftmargin=!,
    format=\definitionlabel,
}
\newcommand\definitionlabel[2][l]{\eqmakebox[listlabel@\EnumitemId][#1]{#2}}

\newlist{issue}{enumerate}{2} % <- pick a larger number if you want to nest these
\crefname{issuei}{issue}{issues}
\Crefname{issuei}{Issue}{Issues}
\crefname{issueii}{issue}{issues}
\Crefname{issueii}{Issue}{Issues}

\newlist{resource}{description}{2} % <- pick a larger number if you want to nest these
\setlist[resource]{
    labelwidth=\eqboxwidth{listlabel@\EnumitemId},
    leftmargin=!,
    format=\resourcelabel,
}
\newcommand\resourcelabel[2][l]{\eqmakebox[listlabel@\EnumitemId][#1]{#2}}

\ExplSyntaxOn
\NewDocumentCommand\enginedetails{}%
  {
    \c_sys_engine_exec_str
    \c_space_tl
    \c_sys_engine_version_str
    \c_space_tl
    (\c_sys_engine_format_str)
  }
\ExplSyntaxOff

\newcommand \fullcref [1]
   { \ifthenelse {\equal{\nameref{#1}}{}}
       {\cref{#1}}
       {\cref{#1} (\nameref{#1})}
   }

\title{Unicode Implementation Issues%
  \thanks
    {
    This is a working document for the Rexx Language Association (RexxLA).
    There will be one or more separate requirements documents.
    It is written in \LaTeX\ \fmtversion\ and was rendered \today\ using \enginedetails.
    }
  }
\author{Shmuel (Seymour J.) Metz}

\begin{document}
\lstset{language=Rexx, extendedchars=true, frame=trbl, escapechar={!}, linewidth=20em}

\maketitle

\begin{abstract}
Classic Rexx supports character code pages in which every character can be represented in a single octet,
and treats only ASCII letters as alphabetic.
Unicode is nominally a 32-bit character set, with code points restricted to 17 16-bit planes,
i.e., code points U+00 through U+10FFFF.
This document describes basic issues and solutions for extending Rexx to support Unicode.
\end{abstract}

\tableofcontents


\section{Background}
The Architecture Review board is investigating areas in which Rexx may be
in need of enhancements, some of which are listed in \cite{ARB:Issues}.
Many modern languages support Unicode encoded as
\href{https://datatracker.ietf.org/doc/rfc3629/}{UTF-8} (\cite{RFC:3629}),
and the \href{https://www.ietf.org/}{IETF}, in \cite{RFC:5198},
has mandated the use of UTF-8 with NFC in new protocols.
Rexx will need to support UTF-8 if it is not to become a backwater,
and that support should not break existing code.
Elaboration of this issue may be added to \cite{ARB:Issues} \cref{issue:MB,issue:UTF-8}.


\section{Scope}
This document only describes issues related to \cref{issue:EA,issue:MB}, expanded alphabet and
multi-octet representations of characters in Unicode \cref{issue:MB,issue:UTF-8}; it does not
address such issues as bidirectional text, nor does it address legacy
DBCS support. It presents suggested solutions for requirements that
are presented in other documents.  Also, most of the details are under
active discussion, so everything here is provisional.
Information on Unicode may be found at \citetitle{Unicode} and \citetitle{UFAQs}.

This document concentrates on classic Rexx, ANSI Rexx and ooRexx; the
implementations most relevant are ooRexx and Regina.  However, cREXX
and NetRexx must be taken into account in order to avoid unnecessary
differences.


\section{Nomenclature}

The definitions given in \cite{USTD:Gloss} and \cite{Unicode} take
precedence over those given here. Quoted text is taken from those sources.
Except for definitions taken from official IETF and Unicode documents,
the nomenclature used here is illustrative rather than normative;
language design teams will formally define, e.g., method names, encoding of parameters.
Most of the sections assume that there will be destinct string types
for extended grapheme clusters (\cref{issue:NT,issue:c2u}), Unicode code points (\cref{issue:NT,issue:c2u}),
legacy code pages (\cref{issue:Leg,issue:mLS,issue:iconv})
and raw octets (\cref{issue:ROS,issue:NT,issue:mO}). However, there has been discussion of including
metadata, in which case come of the classes might be merged.

Some of the nomenclature used in this document, including
the illustrative class names \textbf{BYTES}, \textbf{CODEPOINTS} and \textbf{TEXT}
is taken from the RXU preprocessor of The Unicode Tools of Rexx (TUTOR).
It is planned to encorporate more vocabulary from RXU in subsequent revisions.

The word \textbf{text} has its generic meaning unless given in upper case.

An \underline{underscored} term in a list of options is the default.
Terms separated by the Or symbol (|) are mutually exclussive alternatives.
Terms in brackets are optional.

The bold character \textbf{\'{ }} in examples refers to
U+0301, COMBINING ACUTE ACCENT.
The characters \textbf{\'{E}} and \textbf{\'{e}} in examples refer to the
composed characters U+C9, LATIN CAPITAL LETTER E WITH ACUTE and
U+E9, LATIN SMALL LETTER E WITH ACUTE, not to the decomposed clusters
<U+0045, U+0301> and <U+0065, U+0301>.

Some code samples use ooRexx notation. Those samples are illustrative rather than normative.

References to requirments in \cref{ARBiss} \nameref{ARBiss} are by number.


\section{Statement of problems}

\subsection{Character width}

In Rexx, everything is a string; there are no classes, declarations or types. (\cref{issue:Leg})

While the ANSI standard does not mandate any particular character width for \textbf{Config\_C2B()},
most if not all implementations use a width of 8,
and the length of \textbf{c2x(}\textit{foo}\textbf{)}
is twice the length of \textit{foo}. (\cref{issue:c2x,issue:c2xW})

A large body of existing code operates on binary data from external files,
or accessed from memory via the \textbf{storage()} BIF,
under the assumption that, e.g., \textbf{c2x()}, left(), \textbf{right()}, \textbf{substr()}, operate on octets(]cref{issue:ROS,issue:mO}.
A UTF-8 introducer is treated the same as any other value.

A large body of existing code operates on text under the assumption
that those facilities operate on characters. (\cref{issue:US})

The two categories overlap.

There is no conflict as long as each character is contained within a single octet.
However, Unicode has code points beyond U+FF,
and UTF-8 encoding of non-ASCII Unicode characters will
require more than a single octet even for code points less than U+100 if they are beyond U+7F.

For example, the Unicode string "Caf\'{e}" has 4 code points, 4
grapheme clusters and 5 octets in UTF-8 encoding while
"Cafe\textbf{\'{ }}" has 5 code points, 4 grapheme clusters and 6 octets
in UTF-8 encoding (\cref{issue:NT}), yet many text processing applications need to treat
them as equivalent.

\subsection{Case conversion}
Rexx has built-in case conversion, but it is based on ASCII and
can't even convert the accented letters found in, e.g., ISO-8859-1
(Latin-1), ISO-8859-15 (Latin-9), much less all those found in Unicode.

\begin{lstlisting}[caption={Non-ASCII upper casing in classic Rexx}]
    foo = 'Ren!\'{e}!'
    parse upper var foo bar
\end{lstlisting}

sets bar to REN\'{e} rather than to REN\'{E}.

\subsection{\textbf{xrange()}}
In current implementations the range of characters is extremely small,
and thus the \textbf{xrange()} only returns short strings. (\cref{issue:xr})
With Unicode the range expands to U+00 through U+10FFFF.
That is far too large to allow as either an explict or implicit range in \textbf{xrange()}.

\subsection{Numeric string conversion to characters}
\label{problem:numeric}
The definitions of binary and hexadecimal literals, and of the b2c()
and x2c() functions, in \cite{ANSI:J18}, depend on Config\_B2C. While the
definition"Translate Binary to a coded string." of Config\_B2C in ANSI
X3J18-1996 is rather vague, it is adequate when the character set is
restricted to an 8-bit character set.  The definition must be replaced
by one that is unamgiguous when applied to Unicode.
(\cref{issue:CUC}) There are several obvious options.

\begin{enumerate}
\item Treat every 32 bits as a Unicode scalar
\item Treat every 8 bits as part of a UTF-8 sequence
\item Treat every 8 bits as a character in a legacy code page.
\end{enumerate}

Each of these options has disadvantages.

The converse issue exists for Config\_C2B.

\subsection{Identifiers, labels and procedure names}
The current definition restricts symbols to ASCII characters, which
excludes letters used in many languages. If the rules are extended, in
accordance with \cite{UAX31}. to include Unicode letters and digits
beyond ASCII, the rules for equality of symbols must be addressed.
Are composed and decomposed strings identical? Are base characters
identical to their compatibility alterrnates? Are subscript and
superscript digits distinct from their ASCII counterparts?

When a numeric value is used as a label or procedure name, a precise
definition of the semantics is needed.  This is essentially the same
issue as \fullcref{problem:numeric} above.

When dealing with Unicode, different code sequences may have identical
rendering due to the existence of both fully composed and combining
code points and the exixtence of compatibility code points.
Rexx needs a way to test two Unicode strings for equivalence.
(\cref{issue:SNO,issue:NFCD,issue:NFKCD})

\subsection{PARSE}
The PARSE tempates currently support spliiting text based on a
restricted set of whitespace characters.  A decision must be made
whether to only support space and tab as whitespace for PARSE, or to
use one of the whitespace definitions in \cite{UAX31}.

\subsection{Status of legacy code pages}
There has been some discussion claiming a need to continue supporting legacy code pages. (\cref{issue:LCPS,issue:mLS,issue:iconv})

\subsection{Unassigned and invalid code points}
There has been some discussion of the need to detect
unassigned\footnote{Unsigned is not the same as noncharacter.}
code points. (\cref{issue:UICP,issue:ED})

\subsection{New notation}
Unicode introduces new notation, which Rexx currently doesn't support, e.g., U+xxxx, <codepoint, ...>.

\subsection{Tools}
There are tools available that manipilate Rexx source code in various
ways, e.g., code completion, cross referencing, navigation, prettyprinting, syntax highligting.
These tools may not handle new syntax added in support of Unicode. Examples include
\begin{itemize}
\item The IBM Z\textregistered Open Editor \\
A Rexx Language Support plugin for Visual Studio Code
\item The \LaTeX\  package \href{https://www.ctan.org/pkg/listings}{\textbf{listings}}
\item The \LaTeX \ package \href{https://www.ctan.org/pkg/minted}{\textbf{minted}}
\item The Python package \href{https://pygments.org/}{\textbf{Pygments}}
\end{itemize}


\section{ARB GitHub Issues}
\label{ARBiss}

This section lists all issues in \cite{ARB:Issues}, whether or not they relate to Unicode.

\begin{issue}[label=I.\arabic*,ref=\fbox{I.\arabic*}]
\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35730857}%
{Expanded Alphabets}}
\label{issue:EA}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35730866}%
{Multi-Byte Representations}}
\label{issue:MB}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35730964}%
{Unicode Strings}}
\label{issue:US}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35730903}%
{Unassigned \& Invalid Code Points}}
\label{issue:UICP}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35730928}%
{Error Detection}}
\label{issue:ED}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35730846}%
{UTF-8 Support}}
\label{issue:UTF-8}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35730880}%
{Identifiers \& Allowable Formats}}
\label{issue:IAF}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35730910}%
{New Notation (e.g., U+xxxx)}}
\label{issue:NN}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35730970}%
{Constants for Unicode Characters}}
\label{issue:CUC}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35730937}%
{Case Folding}}
\label{issue:CF}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35731043}%
{Caseless Comparisons}}
\label{issue:CComp}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35730872}%
{Case Conversion}}
\label{issue:CConv}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35730976}%
{Coercions}}
\label{issue:C}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35731061}%
{Strict / Non-strict operators}}
\label{issue:SNO}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35730954}%
{Legacy Strings}}
\label{issue:Leg}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35730887}%
{Legacy Code Pages Support}}
\label{issue:LCPS}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35730947}%
{Raw Octet Strings}}
\label{issue:ROS}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35730934}%
{I/O Methods}}
\label{issue:I/O}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35753880}%
{IO Random Access}}
\label{issue:RA}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35801621}%
{New Text Functions}}
\label{issue:NT}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35731024}%
{NFC \& NFD Functions}}
\label{issue:NFCD}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35731034}%
{NFKC \& NFKD Functions}}
\label{issue:NFKCD}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35730987}%
{c2x() Function}}
\label{issue:c2x}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35731048}%
{Width Parameters for c2x()}}
\label{issue:c2xW}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35730995}%
{c2u() Function}}
\label{issue:c2u}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35731000}%
{makeCodePointString Function}}
\label{issue:mCPS}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35731003}%
{makeGraphemClusterString Function}}
\label{issue:mGCS}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35731012}%
{makeLegacyString Function}}
\label{issue:mLS}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35731020}%
{makeOctets Function}}
\label{issue:mO}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35731039}%
{iconv Function}}
\label{issue:iconv}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35730875}%
{xrange() Function}}
\label{issue:xr}

\item{\href{https://github.com/users/RexxLA/projects/2/views/6?pane=issue&itemId=35731055}%
{PARSE Instruction}}
\label{issue:P}

\end{issue}


\section{Solutions}

Most of this section assumes that there will be three distict string
types, (\cref{issue:mCPS,issue:mGCS,issue:mO}),
and that some methods will not exist in all three types, or
will behave differently.
The type names used here are placeholders, and will be replaced once
there is consensus on what to call them.

\subsection{\textbf{OPTIONS} statement or directive}

Define an option on the OPTIONS statement, or on a similar directive,
to specify either raw octets or Unicode characters.
This breaks programs that operate on both binary data and text.

OPTIONS might also specify a source encoding parameter, overriding any
code page in an environment variable or file metadata.

\begin{definition}
\item[SOURCECP=] Encoding of the Rexx source code
\item[LITERALS=] Type of string constant with no suffix
\begin{definition}
\item[BYTES] Raw octets
\item[CODEPOINTS] Unicode by code point
\item[LEGACY] Legacy 8-bit characters
\item[\underline{TEXT}] Unicode by extended grapheme cluster
\end{definition}
\end{definition}

\subsubsection{RXU OPTIONS values}

The RXU preprocessor accepts these\cite{RXU:OPT} values on the OPTIONS statement:

\begin{definition}
\item[DEFAULTSTRING \textit{default}] where \textit{default} determines the type of a string literal with no suffix:
\begin{definition}
\item[\underline{BYTES}]Y
\item[CODEPOINTS]P
\item[NONE]
\item[TEXT]T
\end{definition}
\item[COERCIONS \textit{ucoercion}] where \textit{ucoercion} determines the result of an operation on strings of mixed string types:
\begin{definition}
\item[DEMOTE]Type of lowest operand
\item[LEFT]Type of left operand
\item[NONE]Raise SYNTAX
\item[\underline{PROMOTE}]Type of highest operand
\item[RIGHT]Type of right operand
\end{definition}
\end{definition}


\subsection{Classes and types}

Allow Rexx variables to contain three distinct types of data: raw octets, Unicode code points and text,
(\cref{issue:mCPS,issue:mGCS,issue:mO}),

Define \textbf{storage()} as returning raw octets,
and provide conversion functions ("casts").
There is an ongoing discussion as to whether all three are needed.

There should be no implicit conversion between \textbf{.BYTES} and Unicode strings.

There should be implicit conversion between Unicode types, but it need not be reversible, i.e.,
a conversion from .CODEPOINTS to .TEXT and back need not produce the same code points as the original

If support for legacy code pages is needed, a fourth string type could be defined.
Strings of this type could include a code page attribute.

For ooRexx a single class with distinguishing attributes could be
used, or a separate class for each type.

RXU uses BYTES for both octet strings and legacy strings.

\subsection{Width parameters for c2x()}

Add a width parameter to \textbf{c2x()} for Unicode code point string
(\cref{issue:c2xW})
(raw octet strings may require input and output widths for UCS-2 AND UTF-16 data, and the
utility of \textbf{c2x()} for grapheme clusters needs more
analysis), and raise conditions with distinct error codes if any code
point is out of range or if an invalid UTF-8 sequence is detected.  A
case could be made for using either the bit size or the digit size as
the width.

Assuming that the width is in in terms of octets
\begin{lstlisting}[%
    caption={c2x() with width parameter},%
    linewidth=35em%
    ]
    foo = 'Ren!\'{e}!'
    bar = foo~UTF-8
    /* assumes that width parameter is in octets */
    say foo~c2x(2) /* Displays 00520065006E00E9  */
    say bar~c2x    /* Displays 52656EC3A9        */
\end{lstlisting}

There is an ongoing discussion as to whether an when to allow implicit coercions of type in, e.g.,
\begin{lstlisting}[
    caption={Implicit coercion},%
    linewidth=35em]%
    ]
    foo = .BYTES~new
    foo = 'Ren!\'{e}!'
    !\textellipsis!
    parse var foo ASCII !{\textquotesingle}\'{e}{\textquotesingle}! .
    say ASCII                     /* Displays Ren */
\end{lstlisting}

If there is no raw octet string added to the language,
then \textbf{c2x()} might behave differently depending on whether an explicit width is provided.

\subsection{RXU c2x() and c2u()}
In RXU, \textbf{c2x()} for Unicode code point strings returns the
hexadecimal values of UTF-8 sequences rather than the hexadecimal
values of unicode scalars. The second parameter of \textbf{c2u()}
controls the output format, and \textbf{c2x(foo,UTF-32)} returns space
separated Unicode scalars.

\subsection{Constants}
Other languages allow specifying Unicode characters using either
the hexadecimal value of the code point or the assigned name of the code point,
(\cref{issue:CUC})
e.g., U+E9
(\cref{issue:NN})
might be coded as {\textbackslash}u\{E9\} or {\textbackslash}u[LATIN SMALL LETTER E WITH ACUTE].
The syntax used for such constants should be consisten across Rexx variants,
including rules for optional spaces between (hex) digits,
and should take into account the recommendations in \cite{RFC:5137}.
Implementations should use the machine readable data bases published by
the Unicode Consortium in order to ease migration to new versions of Unicode.

The form {\textquotesingle}U+digits U+digits ...{\textquotesingle}U is clearer,
but may break code that abuts the variable U with a string literal.
The form {\textquotesingle}U+digits U+digits ...{\textquotesingle}X is acceptable.
There should be a discussion of syntax for named Unicode constants, e.g.,
{\textquotesingle}[COMBINING ACUTE ACCENT]{\textquotesingle}U is
equivalent to {\textquotesingle}U+0301{\textquotesingle}U.
There has been some discussion of using the form
{\textquotesingle}\textellipsis{\textquotesingle}T and of escape conventions
used in other languages.

Binary and hexadecimal literals are of type \textbf{.BYTES} and cannot be implicitly coerced to Unicode strings.
Other string literals are legacy or Unicode and cannot be implictly coerced to \textbf{.BYTES}.

An alternative is to add a new notation using the ASCII \verb|`| as a
framing character. This has the potential issue that it may be
difficult to visually distinguish  \verb|`| from  \verb|'|.

Another alternative is to use literals of the forms
{\textquotesingle}\textellipsis{\textquotesingle}type:codepage,
{\textquotesingle}\textellipsis{\textquotesingle}U:codepoints and
{\textquotesingle}\textellipsis{\textquotesingle}U:clusters. However,
that makes it incompatinle with ooRexx.

The forms {\textquotesingle}\textellipsis{\textquotesingle}\{modifier\} and
{\textquotesingle}\textellipsis{\textquotesingle}type\{modifier\}
have no obvious conflict with existing syntax and has no abutment issues.

The following table is intended as a discussion point and should be updated whenever a consencuss is reached.

\begin{tabular}{| l | l | l |}
\hline
Example & Type & Semantics \\
\hline
{\textquotesingle}Ren\'{e}{\textquotesingle}               & CODEPOINTS & Unicode text by code point             \\
                                                           & TEXT       & Unicode text by grapheme cluster (TBD) \\
\hline
{\textquotesingle}U+00E9{\textquotesingle}R                & CODEPOINTS & Unicode text by code point             \\
\hline
{\textquotesingle}U+00E9{\textquotesingle}CODEPOINTS       & CODEPOINTS & Unicode text by code point             \\
\hline
{\textquotesingle}U+00E9{\textquotesingle}TEXT             & TEXT       & Unicode text by grapheme cluster       \\
\hline
{\textquotesingle}Ren\'{e}{\textquotesingle}\{CODEPOINTS\} & CODEPOINTS & Unicode text by code point             \\
\hline
{\textquotesingle}Ren\'{e}{\textquotesingle}\{TEXT\}       & TEXT       & Unicode text by grapheme cluster       \\
\hline
{\textquotesingle}Ren\'{e}{\textquotesingle}\{ISO8859-1\}  & Legacy     & ISO 8859-1 legacy text                 \\
\hline                                                     & CODEPOINTS & Unicode text by code point             \\
{\verb|`|}Ren\'{e}{\verb|`|}
                                                           & TEXT       & Unicode text by grapheme cluster (TBD) \\
\hline
{\verb|`|}Ren\'{e}{\verb|`|}C                              & CODEPOINTS & Unicode text by code point             \\
\hline
{\verb|`|}Ren\'{e}{\verb|`|}T                              & TEXT       & Unicode text by grapheme cluster       \\
\hline
\end{tabular}
\\
An issue that must be resolved is whether string literals should have
binary fidelity or visual fidelity to the target code page, i.e.,
should the quoted source characters be given in the source code page
or in the target code page.  E.g., should the word "foo" in ISO 8859-1
and in EBCDIC be coded as
{\textquotesingle}foo{\textquotesingle}{ISO8859-1} and
{\textquotesingle}foo{\textquotesingle}{EBCDIC}, requiring that Rexx
translate the text, or should the second be entered with the EBCDIC
code points 86, 96, 96, making it harder to read and edit?

Another issue is whether numeric constants used as labels and call
targets should be treated as strings of legacy code points, UTF-8
sequences or as strings of Unicode scalars.

\subsubsection{RXU string types}

RXU has five types of string literals\cite{RXU:NewTypes}:
\begin{definition}
\item['string'] The type is determined by OPTIONS.
\item['string'P] Unicode by code point
\item['string'T] Unicode by EGC
\item['space separated tokens'U]
Unicode code points by alias, name or hexadecimal value;
the string is BYTES rather than CODEPOINTS or TEXT.
\item['string'Y] Legacy bYte string,can only be promoted if valid UTF-8 sequences
\end{definition}

\subsection{Error detection}
The Rexx standard should specify ehat to do when a string being transformed
contains invalid code points or octet seqiences. (\cref{issue:ED})
The condition names given below are illustrative and not normative.
Unicode BIF/BIMs should detect invalid input and signal the following conditions, with unique error codes.
It is TBD whether some or all of these should be folded into SYNTAX.

\begin{definition}
\item [INVALIDCODEPOINT]%
But carefully read 3.2 Conformance Requirements,
Code Points Unassigned to Abstract Characters, p. 77, in \cite{Unicode}.
\item[INVALIDUTF]%
An invalid UTF-8 octet sequence or invalid use of a UTF-16 surrogate.
\item [NOENCODING]%
The operation requested requires a code page name.
\item [NOTEXT]%
An operation was requested that is not valid for a binary file.
\item [RANGE]%
A code point or other numeric entioty excees the permitted range.
This might occur, e.g., when an application requuires that characters be limited to the BMP.
\end{definition}

\subsection{I/O}

Stream input/output will need additional support for Unicode.
\cref{issue:I/O}
The \textbf{command}  and \textbf{open} methods of the stream classes
should support a \textbf{CODEPAGE} option; attempting to set a
codepage for a binary file should raise a \textbf{NOTTEXT} condition
with a distinct error code.  There should be an option or suboption
controling whether to use Unicode if an apparent BOM is detected.

The default should probably be UTF-8 or ISO 8859-1 with switching to
Unicode if a BOM is detected.

Similarly, there should be an option to distinguish between reading
individual code points and reading EGC; this is needed so that the
\textbf{charin()} BIM can correctly interpret the character count for Unicode input.

Handling seek for variable-width encodings and EGCs is problematical.
\cref{issue:RA}
There are several viable approaches, each with disadvantages.

\begin{itemize}
\item Use octet count, as at present. \\
This risks a program doing a seek within a UTF-8 sequence,
within a UCS-2/UCS-4 character,
within a UTF-16 surrogate pair,
or, for EGC access, within an EGC.
Strategies to ameliorate this include
\begin{definition}
\item [UTF-8]
Read the octet at the specified offset and verify that either the high
bit is 0 or the two high order bits are 1.
\item [UCS-2]
Verify that the offset is a multiple of 2.
\item [UTF-16]
Verify that the offset is a multiple of 2.  Read two octets at the
specified offset and verify that is not a low surrogate (U+DC00-U+DFFF),
\item [UCS-4]
Verify that the offset is a multiple of 2.
Read four bytes and verify that they do not exceed U+10FFFF.
\end{definition}
\item Use character or EGC count \\
This is expensive
\item Define a cursor type. \\
This violates "Everything is a string" in classic Rexx, but is reasonable for ooRexx.
\end{itemize}

Handling update in the middle of a file with variable-width encodings
or EGC access has similar issues, Absent an acceptable way to deal
with it, prohibit update in the middle of a file for anything but
binary and legacy characters.

A discussion is needed on whether and when to create or discard byte order marks.

\subsubsection{RXU I/O}

in RXU, stream I/O\cite{RXU:STREAM} defaults to legacy (BYTES).

RXU adds an \textbf{ENCODING} option to \textbf{STREAM(}\textit{streamid},\textbf{OPEN }\textit{options}\textbf{)}. When this option is used the stream is Unicode enabled, and some stream functions are not allowed.
\textbf{ENCODING} must be followed by the name of then encoding, which for Unicode may in turn be followed by \textit{error} and \textit{target} options:

\begin{itemize}
  \item \underline{\textbf{REPLACE}} \\
  Replace invalid characters with the Unicode Replacement Character (U+FFFd).
  \item \textbf{SYNTAX} \\
  Raise SYNTAX for invalid characters.
  \item \textbf{CODEPOINTS} \\
  Units of codepoints.
  \item \underline{\textbf{TEXT}} \\
  Units of extended grapheme clusters.
\end{itemize}
 
RXU adds  options to  \textbf{STREAM(}\textit{streamid},\textbf{QUERY}\textit{options}\textbf{)}

\begin{itemize}
\item \textbf{Query Encoding Name}
\item \textbf{Query Encoding Target} \\
CODEPOINTS  or TEXT
\item \textbf{Query Encoding Error} \\
REPLACE or SYNTAX
\item \textbf{Query Encoding LastError}
\item \textbf{Query Encoding \\
Everything but LastError}
\end{itemize}

\subsection{Case folding}

Case folding of symbols and caseless comparisons will use the \citetitle{UCD}ENCODING.
\cref{issue:CF,issue:CComp,issue:CConv})
The rules for case folding should take into account mathematical usage.
\begin{itemize}
\item U+1D400 through U+1D7FF are semantically distinct from other letters.
\item Superscripts and subscripts have semantic significance.
\end{itemize}

\subsection{Raw octet strings}
Many exist Rexx programs deal with binary data,
and Rexx has conversion functions to deal with those data,
e.g., c2x, x2c.
(\cref{issue:ROS})
The new version of Rexx will need methods to continue dealing with binary data.
The methods should include those of the ooRexx .string class, except that
\begin{itemize}
\item The unit of operation is the uninterpreted octet.
\item The \textbf{makeString} method requires an encoding parameter.
\item Parameters are raw octet strings.
\item There are no caseless methods.
\end{itemize}

Additional conversion functions will be needed (\cref{issue:NT,issue:mLS,issue:mO}).

\subsection{Legacy strings}

If there is a .Legacy string type then the methods should have the
same semantics as the existing methods for the .string class.
If the new standard has a code page attribute then there should be an
access method for it and the init or new method should allow
specifying the code page.

The following Additional functions and methods should be defined:
\begin{definition}
\item [iconv] %
Convert from one code page to another and return a legacy string. (\cref{issue:iconv})
\item [makeCodePageString] %
Return a Unicode string in which individual code points can be accessed. (\cref{issue:mCPS})
\item [makeGraphemClusterString] %
Return a Unicode string in which only complete grapheme clusters can be accessed. (\cref{issue:mGCS})
\end{definition}

\subsection{Unicode strings}

There should be subtypes depending on whether the
unit of operation is the Unicode code point or the grapheme cluster. (\cref{issue:US})
The methods should be those of the ooRexx .string class except:
\begin{itemize}
\item there should be a BIF for each in order to allow use in classic Rexx.
\item Discuss how and whether to introduce equivalent operators.
\item discuss whether \textbf{=} should ignore all leading and trailing whitespace
or only leading and trailing blanks. Discuss need for other equality tests.
\item \textbf{==} tests for absolute equality for CODEPOINTS but
EGC equivalence for TEXT.
Discuss which of the Unicode equality tests to use and,
if more than one, which is primary.
\item
The caseless comparisons will use the \cite{UCD}.
(\cref{issue:CComp})
There will be variants to preserve or remove accents\footnote{Is Enye (\~n) considered an accented letter?}.
\item There should be no \textbf{bit\textellipsis} methods.
\item Add an optional third parameter to the \textbf{upper} and \textbf{lower} methods
to control whether to translate mon-ASCII characters and whether to strip accents.
\item
The following Additional functions and methods should be defined:
\begin{definition}
\item[c2u] Return code points in Unicode notation. Possible options include
\begin{itemize}
\item U+xxxx or bare hexadecimal
\item frame in <> and separate with commas
\item indicate EGC boundaries
\item indicate properties
\end{itemize}
\item [makeCodePageString]
Return a Unicode string in which individual code points can be accessed (\cref{issue:mCPS})
\item [makeGraphemClusterString]
Return a Unicode string in which only complete grapheme clusters can be accessed (\cref{issue:mGCS})
\item [makeLegacyString]
Return a legacy string for the specified code page in which individual octets can be accessed (\cref{issue:LCPS,issue:mLS})
\item [makeOctets]
Return a raw octet string using a specified encoding.\footnote{default
to UTF-8 or raise NOENCODING if no encoding specified?} (\cref{issue:mO})
\item [NFC] Return a string normalized with Normalization Form C (\cref{issue:NFCD})
\item [NFD] Return a string normalized with Normalization Form D (\cref{issue:NFCD})
\end{definition}
\end{itemize}

There should be a description of how to handle conversion from Unicode code
points and grapheme clusters that do not exist in the target code page.
(\cref{issue:ED,issue:Leg,issue:iconv})
\begin{itemize}
\item Replace with U+1A (SUB) or other specified character
\item Raise SYNTAX with a unique error code
\item Raise a new condition name with a unique error code
\end{itemize}

\subsection{Functions and methods}
The following table summarizes some of the methods that differ among string types. 
With the exceptions of \textbf{{[}{]}}, \textbf{makeArray} and \textbf{makeString},
there is an operator or polymorphic BIF for each BIM listed.

\begin{tabular}{| l | c | c | c | c |}
\hline
Method               & \textbf{.Legacy} & \textbf{.BYTES}  & \textbf{.CODEPOINTS}  & \textbf{TEXT} \\
\hline
\textbf{{[}{]}}      & by octet         & by octet         & by code point  & by cluster    \\
\textbf{\&}          & by octet         & \textbf{n/a}     & by code point  & by cluster    \\
\textbf{|}           & by octet         & \textbf{n/a}     & by code point  & by cluster    \\
\textbf{\&\&}        & by octet         & \textbf{n/a}     & by code point  & by cluster    \\
\textbf{=}           & by octet         & by octet         & by code point  & by cluster    \\
\textbf{==}          & by octet         & by octet         & by code point  & by cluster    \\
\textbf{{\neg}=}     & by octet         & by octet         & by code point  & by cluster    \\
\textbf{><}          & by octet         & by octet         & by code point  & by cluster    \\
\textbf{<>}          & by octet         & by octet         & by code point  & by cluster    \\
\textbf{<}           & by octet         & by octet         & by code point  & by cluster    \\
\textbf{<=}          & by octet         & by octet         & by code point  & by cluster    \\
\textbf{>}           & by octet         & by octet         & by code point  & by cluster    \\
\textbf{{\neg}>}     & by octet         & by octet         & by code point  & by cluster    \\
\textbf{abbrev}      & by octet         & by octet         & by code point  & by cluster    \\
\textbf{bitand}      & \textbf{n/a}     & by octet         & \textbf{n/a}   & \textbf{n/a}  \\
\textbf{bitor}       & \textbf{n/a}     & by octet         & \textbf{n/a}   & \textbf{n/a}  \\
\textbf{bitxor}      & \textbf{n/a}     & by octet         & \textbf{n/a}   & \textbf{n/a}  \\
\textbf{c2b}         & 8 bits           & default 8 bits   & Explicit width & \textbf{n/a}  \\
\textbf{c2x}         & 8 bits           & default 8 bits   & Explicit width & \textbf{n/a}  \\
\textbf{center}      & by octet         & \textbf{n/a}     & by code point  & by cluster    \\
\textbf{change}      & by octet         & by octet         & by code point  & by cluster    \\
\textbf{find}        & by octet         & by octet         & by code point  & by cluster    \\
\textbf{index}       & by octet         & by octet         & by code point  & by cluster    \\
\textbf{left}        & by octet         & by octet         & by code point  & by cluster    \\
\textbf{makeArray}   & by octet         & by octet         & by code point  & by cluster    \\
\textbf{makeString}  & by octet         & by octet         & by code point  & by cluster    \\
\textbf{pos}         & by octet         & by octet         & by code point  & by cluster    \\
\textbf{right}       & by octet         & by octet         & by code point  & by cluster    \\
\textbf{strip}       & by octet         & by octet         & by code point  & by cluster    \\
\textbf{substr}      & by octet         & by octet         & by code point  & by cluster    \\
\textbf{verify}      & by octet         & by octet         & by code point  & by cluster    \\
\hline
\end{tabular}
\\*
\\*
The backslash ("\textbackslash") may be used in place of the Logical Not ("\neg").

In addition, the makeString and makeString methods should allow caseless option
parameters to control the class and attributes of the returned array
elements or string, including:

\begin{definition}
\item [Clusters] Unicode text with extended grapeme clusters as the abstract units.
\item [Codepoints] Unicode text with Unicode scalars as the abstract units.
\item [cp=legacy code page] Legacy or octet string with specified encoding.
\item [cp=UTF-8]
Legacy or octet string with UTF-8 encoding;
functions like center and left will give unexpected results.
\item [Legacy] Legacy string with default encoding unless cp= is also specified.
\item [raw] Raw octet string; cp= must be specified.
\end{definition}

\subsubsection{RXU functions and methods}

RXU adds the \textbf{DECODE} and \textbf{ENCODE} methods in the Unicode class. These provide an easy way to implement the proposed \textbf{iconv} function.

RXU adds these\cite{RXU:NewBIFs} additional built-in functions:

\begin{itemize}
\item \textbf{BYTES}
\item \textbf{C2U}
\item \textbf{CODEPOINTS}
\item \textbf{GRAPHEMES}
\item \textbf{N2P}
\item \textbf{P2N}
\item \textbf{STRINGTYPE}
\item \textbf{TEXT}
\item \textbf{UNICODE(}\textit{string},\textit{function}\textbf{)} \\
Performs the named function on \textit{string}:
\begin{description}
\item[isNFD] Returns 1 if string is in normalized form D
\item[toLowercase]
Returns upper case translatio.
\item[toUpercase]
Returns lower case translation
\item[toNFD] Normalizes to form D (decomposed)
\end{description}
\item \textbf{UNICODE(}\textit{codepoint},\textbf{PROPERTY},\textit{property}\textbf{)} \\
Retrieves the value of the named property
\item \textbf{UTF8} \\
Validates a UTF-8 string and optionally converts it to a different Unicode transform.
\end{itemize}

RXU modifies some of the standard functions. In general, it assumes and exposes a UTF-8 representation. Also, not all functions are available for all string types. The functions modified by RXU are:

\begin{itemize}
\item \textbf{C2X}
\item \textbf{CHARIN}
\item \textbf{CHAROUT}
\item \textbf{CHARS}
\item \textbf{CENTER}
\item \textbf{CENTRE}
\item \textbf{COPIES}
\item \textbf{DATATYPE}
\item \textbf{LEFT}
\item \textbf{LENGTH}
\item \textbf{LINEIN}
\item \textbf{INEOUT}
\item \textbf{LINES}
\item \textbf{LOWER}
\item \textbf{POS}
\item \textbf{REVERSE}
\item \textbf{RIGHT}
\item \textbf{STREAM}
\item \textbf{SUBSTR}
\item \textbf{UPPER}
\end{itemize}

\subsection{Coercions}
In addition to explicit casts via BIF/BIM, the following promotions
from code-point strings to grapheme-cluster strings will be automatic
\cref{issue:C})

\begin{itemize}
\item Concatenation of code-point strings with grapheme-cluster strings.
will be grapheme-cluster strings.
\item Code point search arguments for grapheme-cluster strings.
will be coerced to grapheme-cluster strings.
\item Legacy strings tagged to a code page, in a context that requires Unicode,
will be converted to the appropriate Unicode string type.
\end{itemize}

There will be no automatic promotion for octet strings, Unicode to
legacy nor for legacy strings without code page tagging.


\section{Glossary}


The definitions given in \cite{USTD:Gloss} and \cite{Unicode} take
precedence over those given here. Quoted text is taken from those sources, or from IETF documents.
Except for definitions taken from official IETF and Unicode documents,
the nomenclature used here is illustrative rather than normative;
language design teams will formally define, e.g., method names, encoding of parameters.

\begin{definition}
\item [.BYTES] The string class for uninterprted octet strings.
\item [.CODEPOINTS] The string class for strings of Unicode code points.
\item [.Legacy] The string class for strings in legacy code pages.
May be merged with .BYTES.
\item [.TEXT] The string class for strings of Unicod extended grapheme clusters.
\item[ARB] RexxLA Architecture Review Board
\item [Bidi] "Abbreviation of bidirectional, in reference to mixed left-to-right and right-to-left text."
\item [BIF] Built In Function
\item [BIM] Built In Method
\item [Block] "A grouping of characters within the Unicode encoding
space used for organizing code charts. Each block is a uniquely named,
continuous, non-overlapping range of code points, containing a
multiple of 16 code points, and starting at a location that is a
multiple of 16. A block may contain unassigned code points, which are
reserved."
\item [BMP] Basic Multilingual Plane\index{BMP!definition}index{BMP!Basic Multilingual Plane!definition}
\\*
The first 64 Ki code points of Unicode, from U+0000 to U+FFFF.
\item [BOM] Byte Order Mark: U+FEFF, ZERO WIDTH NON-BREAKING SPACE (ZWNBSP)
\\*
Used as the first character to indicate byte order for UCS-2, UTF-16 and UCS-4;
\\*
Optional as the first character for UTF-8.
\item [encoded character] The smallest constituant of a Unicode string.
"The Unicode Standard does not define what is and is not a text
element in different processes; instead, it defines elements called
encoded characters. An encoded character is represented by a number
from 0 to 10FFFF\textsubscript{16} called a code point."
\item [EGC] Extended grapheme cluster
\item [GCGID] "Acronym for Graphic Character Global Identifier.
These are listed in the IBM document
Character Data Representation Architecture, Level 1, Registry SC09-1391."
See \url{https://www.ibm.com/downloads/cas/G01BQVRV}.
\item [grapheme cluster]
"A grapheme cluster consists of a base character followed by any
number of continuing characters, where acontinuing character may
include any nonspacing combining mark, certain spacing combining
marks, or a join control."
{\cite{UAX29}} defines two types of grapheme clusters;
"An extended grapheme cluster is the same as a legacy grapheme cluster,
with the addition of some other characters.
The continuing characters are extended to include all spacing combining marks,
such as the spacing (but dependent) vowel signs in Indic scripts."
\item [high surrogate] A code point in the range U+D800-U+DBFF, used
as the first half of a surrogate pair.
\item [IETF] \href{https://ietf.org}{Internet Engineering Task Force}
\item [introducer] The first octet in the UTF-8 encoding of a Unicode character beyond U+7F
\item [low surrogate] A code point in the range U+DC00-U+DFFF, used
as the second half of a surrogate pair.
\item [NFC]  Unicode
"Normalization Form C (NFC). A normalization form that erases any
canonical differences, and generally produces a composed result. For
example, a + umlaut is converted to \symbol{"00E4} in this form. This form most
closely matches legacy usage. The formal definition is D120 in Section
3.11, Normalization Forms."
\\*
the normalization endorsed by the IETF
\item [NFD] Unicode
"Normalization Form D (NFD). A normalization form that erases any
canonical differences, and produces a decomposed result. For example,
\symbol{"00E4} is converted to a + umlaut in this form. This form is most often
used in internal processing, such as in collation. The formal
definition is D118 in Section 3.11, Normalization Forms."

\item [NFKC] Unicode
"Normalization Form KC (NFKC). A normalization form that erases both
canonical and compatibility differences, and generally produces a
composed result: for example, the single \symbol{"01C6} character is converted to d
+ \symbol{"017E} in this form. This form is commonly used in matching. The formal
definition is D121 in Section 3.11, Normalization Forms."

\item [NFKD] Unicode
"Normalization Form KD (NFKD). A normalization form that erases both
canonical and compatibility differences, and produces a decomposed
result: for example, the single \symbol{"01C6} character is converted to d + z +
caron in this form. The formal definition is D119 in Section 3.11,
Normalization Forms."

\item [octet] 8-bit byte
\item [Plane] "A range of 65,536 (1000016) contiguous Unicode code
points, where the first code point is an integer multipleof 65,536
(1000016). Planes are numbered from 0 to 16, with the number being the
first code point of the plane divided by 65,536. Thus Plane 0 is
U+0000..U+FFFF, Plane 1 is U+10000..U+1FFFF, ..., and Plane 16 (1016)
is U+100000..10FFFF. (Note that ISO/IEC 10646 uses hexadecimal
notation for the plane numbers-for example, Plane B instead of Plane
11). (See Basic Multilingual Plane and supplementary planes.)"
\item [RFC] Request For Comments
\\*
A formal document published by the IETF defining, e.g., a protocol.
RFC documents contain technical specifications and organizational notes for the Internet.
\begin{itemize}
  \item Best Current Practice (BCP)
  \item Experimental
  \item Informational
  \item Proposed Standard
  \item Internet Standard (STD)
  \item Historic
\end{itemize}
\item [surrogate] A code point in the range U+D800-U+DFFF used to
encode 21-bit code points into pairs of 16-bit bytes.
\item [surrogate pair] A high surrogate (in the range U+D800-U+DBFF)
followed by a low surrogate (in the range U+DC00-U+DFFF),
collectively representing a 21-bit code point.
\item [TBD] To Be Determined.
\item [UCS] Universal Character Set, ISO 10646, roughly equivalent to Unicode
\item [UCS-2] A 16 bit subset of Unicode, containing only the BMP.
\item [Unicode Consortium] A non-profit corporation devoted to
developing, maintaining, and promoting software internationalization standards and data.
\item [UTF-8] UCS Transformation Format 8
(\cite{USTD:3.9} and \cite{RFC:3629}).
\\*
The encoding of Unicode endorsed by the IETF
\item [UTF-8 octet sequence]
The sequence of octets representing a single Unicode code point.
It may consist of a single ASCII character padded on the left with a zero bit,
or of a one octet introducers followed by a 1-3 octet tail.

\begin{tabular}{| r | l |}
\hline
Code points & UTF-8 octet sequence \\
\hline
U+0000 - U+007F    & 0xxxxxxx \\
\hline
U+0080 - U+07FF    & 110xxxxx 10xxxxxx \\
\hline
U+0800 - U+FFFF    & 1110xxxx 10xxxxxx 10xxxxxx \\
\hline
U+10000 - U+10FFFF & 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx \\
\hline
\end{tabular}
\item [UTF-16] UCS Transformation Format 16
(\cite{USTD:3.9} and \cite{RFC:2781}).
\end{definition}


\section{Resources}
There are some useful tools available on the WWW:

\begin{resource}
\item[CLDR]%
\href{https://cldr.unicode.org/index/downloads}%
{CLDR Releases/Downloads}

\item[Compart Unicode]%
\href{https://www.compart.com/en/unicode/}%
{Look up, e.g., code point.}

\item[TUTOR]%
\href{https://github.com/RexxLA/rexx-repository/tree/master/ARB/standards/work-in-progress/unicode/UnicodeTools}%
{The Unicode Tools Of Rexx}

\item[UCD]%
\href{https://www.unicode.org/Public/UCD/latest/}%
{Unicode{\textregistered} Character Database (UCD)}

\item[UCD index]%
\href{https://www.unicode.org/charts/charindex.html}%
{Unicode{\textregistered} Character Name Index}
\end{resource}


\section{Bibliography}
This version of the document prints all included bibliography entries, even those note cited.
\nocite{*}

\printbibliography[%
    keyword=ARB,%
    title={GitHub ARB documents}%
    ]
\printbibliography[%
    keyword=FAQ,%
    title=FAQs%
    ]
\printbibliography[%
    check={standard},%
    notkeyword={FAQ},%
    title={Official documents}%
    ]


\printindex

\end{document}
